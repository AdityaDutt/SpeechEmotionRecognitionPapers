# SpeechEmotionRecognitionPapers

- wav2vec: Unsupervised Pre-training for Speech Recognition, 2019 [Here](https://arxiv.org/pdf/1904.05862.pdf)
  [:white_small_square:Audio ]

- Contrastive Unsupervised Learning for Speech Emotion Recognition, 2021 [Here](https://arxiv.org/pdf/2102.06357.pdf)   [:white_small_square:Audio ]

- Improving Speech Emotion Recognition with Unsupervised Representation Learning on Unlabeled Speech, [Here](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8682541) [:white_small_square:Audio ]
- Adversarial Auto-Encoders for Speech Based Emotion Recognition, 2018 [Here](https://arxiv.org/pdf/1806.02146.pdf) [:white_small_square:Audio ]
- Using regional saliency for speech emotion recognition, [Here](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7952655) [:white_small_square:Audio ]
- Speech Emotion Recognition via Contrastive Loss under Siamese Networks, 2018 [Here](https://arxiv.org/pdf/1910.11174.pdf) [:white_small_square:Audio ]
- End-to-end Triplet Loss based Emotion Embedding System for Speech Emotion Recognition, 2020 [Here](https://arxiv.org/pdf/2010.06200.pdf) [:white_small_square:Audio ]
- Autoencoder With Emotion Embedding for Speech Emotion Recognition, 2021 [Here](Autoencoder With Emotion Embedding for Speech Emotion Recognition) [:white_small_square:Audio ]

- Direct Modelling of Speech Emotion from Raw Speech, 2019 [Here](https://arxiv.org/pdf/1904.03833.pdf) [:white_small_square:Audio ]

-  (2019) Context-Aware Emotion Recognition Networks [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Lee_Context-Aware_Emotion_Recognition_Networks_ICCV_2019_paper.pdf)]
  [:white_small_square:Visual ]

- (2017) A Multimodal Deep Regression Bayesian Network for Affective Video Content Analyses [[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Gan_A_Multimodal_Deep_ICCV_2017_paper.pdf)] 

  [:white_small_square:Visual :white_small_square:Audio]
- (2020) M3ER: Multiplicative Multimodal Emotion Recognition Using Facial, Textual, and Speech Cues [[paper](https://arxiv.org/pdf/1911.05659.pdf)]

  [:white_small_square:Face :white_small_square:Speech :white_small_square:Text ]

- (2020) An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos [[paper](https://aaai.org/Papers/AAAI/2020GB/AAAI-ZhaoS.7155.pdf)]

  [:white_small_square:Visual :white_small_square:Audio ]

- (2019) Multi-Interactive Memory Network for Aspect Based Multimodal Sentiment Analysis [[paper](https://www.aaai.org/ojs/index.php/AAAI/article/view/3807)] 

  [:white_small_square:Visual :white_small_square:Text ]

- (2019) VistaNet: Visual Aspect Attention Network for Multimodal Sentiment Analysis [[paper](https://www.aaai.org/ojs/index.php/AAAI/article/view/3799)] 

  [:white_small_square:Visual :white_small_square:Text ]

- (2019) Cooperative Multimodal Approach to Depression Detection in Twitter [[paper](https://www.aaai.org/ojs/index.php/AAAI/article/view/3775)]

  [:white_small_square:Visual :white_small_square:Text ]

- (2014) Predicting Emotions in User-Generated Videos [[paper](http://www.yugangjiang.info/publication/aaai14-emotions.pdf)] 

  [:white_small_square:Visual :white_small_square:Audio :white_small_square:Attribute ]
